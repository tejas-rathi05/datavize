{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762e55ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "import google.generativeai as genai\n",
    "from langchain.schema import Document\n",
    "\n",
    "def load_page_from_gemini(page_bytes: bytes, page_num: int, file_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Send a single page PDF (in bytes) to Gemini OCR and return extracted text.\n",
    "    \"\"\"\n",
    "    API_KEY = \"your api key\"\n",
    "    genai.configure(api_key=API_KEY)\n",
    "    model = genai.GenerativeModel('gemini-2.5-pro')\n",
    "\n",
    "    # Prepare BytesIO object with name\n",
    "    page_file = io.BytesIO(page_bytes)\n",
    "    page_file.name = f\"page_{page_num}.pdf\"\n",
    "\n",
    "    # âœ… Must provide mime_type for in-memory uploads\n",
    "    sample_file = genai.upload_file(\n",
    "        path=page_file,\n",
    "        display_name=f\"{file_name}-page-{page_num}\",\n",
    "        mime_type=\"application/pdf\"\n",
    "    )\n",
    "\n",
    "    print(f\"Uploaded page {page_num} as: {sample_file.uri}\")\n",
    "\n",
    "    response = model.generate_content([\n",
    "        sample_file,\n",
    "        \"Extract all text from this page, including image descriptions and tables, in a structured format.\"\n",
    "    ])\n",
    "\n",
    "    return response.text\n",
    "\n",
    "\n",
    "def extract_pdf_pagewise(pdf_path: str) -> Document:\n",
    "    \"\"\"\n",
    "    Extract scanned PDF text page by page using Gemini OCR.\n",
    "    \"\"\"\n",
    "    reader = PdfReader(pdf_path)\n",
    "    text = \"\"\n",
    "    file_name = pdf_path.split(\"/\")[-1]\n",
    "\n",
    "    for i in range(len(reader.pages)):\n",
    "        writer = PdfWriter()\n",
    "        writer.add_page(reader.pages[i])\n",
    "\n",
    "        # Page â†’ Bytes\n",
    "        page_bytes = io.BytesIO()\n",
    "        writer.write(page_bytes)\n",
    "        page_bytes.seek(0)\n",
    "\n",
    "        # OCR this page\n",
    "        page_text = load_page_from_gemini(page_bytes.getvalue(), i + 1, file_name)\n",
    "\n",
    "        # Append\n",
    "        text += f\"\\n--- Page {i+1} ---\\n\" + page_text\n",
    "\n",
    "    return Document(page_content=text, metadata={\"source\": file_name})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c278869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"/Users/sameersingh/Documents/DataViz/data/Report on Title 2024-11-18.pdf\"\n",
    "pdf_text = extract_pdf_pagewise(pdf_path)\n",
    "print(pdf_text.page_content[:1000])  # print first 1000 chars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d98b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "import google.generativeai as genai\n",
    "from langchain.schema import Document\n",
    "\n",
    "# ðŸ”‘ Gemini API key\n",
    "API_KEY = \"your api key\"\n",
    "genai.configure(api_key=API_KEY)\n",
    "\n",
    "\n",
    "def load_pdf_chunk_from_gemini(chunk_bytes: bytes, chunk_num: int, file_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Send a multi-page PDF chunk to Gemini OCR and return extracted text.\n",
    "    \"\"\"\n",
    "    model = genai.GenerativeModel(\"gemini-2.5-pro\")\n",
    "\n",
    "    # Gemini needs mime_type if we pass BytesIO\n",
    "    chunk_file = io.BytesIO(chunk_bytes)\n",
    "    chunk_file.name = f\"chunk_{chunk_num}.pdf\"\n",
    "\n",
    "    sample_file = genai.upload_file(\n",
    "        path=chunk_file,\n",
    "        display_name=f\"{file_name}-chunk-{chunk_num}\",\n",
    "        mime_type=\"application/pdf\"\n",
    "    )\n",
    "\n",
    "    print(f\"Uploaded chunk {chunk_num} as: {sample_file.uri}\")\n",
    "\n",
    "    response = model.generate_content([\n",
    "        sample_file,\n",
    "        \"Extract all text (including from images & tables) from this PDF chunk in correct page order. \"\n",
    "        \"Preserve structure and readability.\"\n",
    "    ])\n",
    "\n",
    "    return response.text\n",
    "\n",
    "\n",
    "def extract_pdf_by_chunks(pdf_path: str, pages_per_chunk: int = 10) -> Document:\n",
    "    \"\"\"\n",
    "    Extract scanned PDF text by sending multiple pages at once to Gemini OCR.\n",
    "    \"\"\"\n",
    "    reader = PdfReader(pdf_path)\n",
    "    text = \"\"\n",
    "    file_name = pdf_path.split(\"/\")[-1]\n",
    "\n",
    "    total_pages = len(reader.pages)\n",
    "    chunk_num = 1\n",
    "\n",
    "    for start in range(0, total_pages, pages_per_chunk):\n",
    "        end = min(start + pages_per_chunk, total_pages)\n",
    "\n",
    "        # Collect pages into one chunk\n",
    "        writer = PdfWriter()\n",
    "        for i in range(start, end):\n",
    "            writer.add_page(reader.pages[i])\n",
    "\n",
    "        chunk_bytes = io.BytesIO()\n",
    "        writer.write(chunk_bytes)\n",
    "        chunk_bytes.seek(0)\n",
    "\n",
    "        # OCR this chunk\n",
    "        chunk_text = load_pdf_chunk_from_gemini(chunk_bytes.getvalue(), chunk_num, file_name)\n",
    "\n",
    "        text += f\"\\n--- Chunk {chunk_num} (Pages {start+1}-{end}) ---\\n{chunk_text}\\n\"\n",
    "        chunk_num += 1\n",
    "\n",
    "    return Document(page_content=text, metadata={\"source\": file_name})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b6f481",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"/Users/sameersingh/Documents/DataViz/data/Report on Title 2024-11-18.pdf\"\n",
    "# Example: 200 pages â†’ 10 pages per chunk â†’ 20 API calls\n",
    "result_doc = extract_pdf_by_chunks(pdf_path, pages_per_chunk=10)\n",
    "print(result_doc.page_content[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a2d79c",
   "metadata": {},
   "source": [
    "### using claude for ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60546e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "import anthropic\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Claude client\n",
    "client = anthropic.Anthropic(api_key=\"your api key\")\n",
    "\n",
    "\n",
    "def ocr_pdf_chunk_with_claude(chunk_bytes: bytes, chunk_num: int, file_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Send a multi-page PDF chunk (bytes) to Claude OCR and return extracted text.\n",
    "    \"\"\"\n",
    "    pdf_data = base64.standard_b64encode(chunk_bytes).decode(\"utf-8\")\n",
    "\n",
    "    message = client.messages.create(\n",
    "        model=\"claude-sonnet-4-20250514\",\n",
    "        max_tokens=7000,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"document\",\n",
    "                        \"source\": {\n",
    "                            \"type\": \"base64\",\n",
    "                            \"media_type\": \"application/pdf\",\n",
    "                            \"data\": pdf_data\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": (\n",
    "                            \"Extract all text from this PDF chunk. \"\n",
    "                            \"If there are forms or checkboxes marked by pen, mention them clearly. \"\n",
    "                            \"Preserve the order and formatting.\"\n",
    "                        )\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return message.content[0].text if message.content else \"\"\n",
    "\n",
    "\n",
    "def extract_pdf_by_chunks(pdf_path: str, pages_per_chunk: int = 10) -> Document:\n",
    "    \"\"\"\n",
    "    Extract scanned PDF text by splitting into chunks (e.g., 10 pages each)\n",
    "    and sending each chunk to Claude OCR.\n",
    "    \"\"\"\n",
    "    reader = PdfReader(pdf_path)\n",
    "    text = \"\"\n",
    "    file_name = pdf_path.split(\"/\")[-1]\n",
    "\n",
    "    total_pages = len(reader.pages)\n",
    "    chunk_num = 1\n",
    "\n",
    "    for start in range(0, total_pages, pages_per_chunk):\n",
    "        end = min(start + pages_per_chunk, total_pages)\n",
    "\n",
    "        # Merge multiple pages into one chunk\n",
    "        writer = PdfWriter()\n",
    "        for i in range(start, end):\n",
    "            writer.add_page(reader.pages[i])\n",
    "\n",
    "        chunk_bytes = io.BytesIO()\n",
    "        writer.write(chunk_bytes)\n",
    "        chunk_bytes.seek(0)\n",
    "\n",
    "        # OCR this chunk\n",
    "        print(f\"Processing pages {start+1} to {end}...\")\n",
    "        chunk_text = ocr_pdf_chunk_with_claude(chunk_bytes.getvalue(), chunk_num, file_name)\n",
    "\n",
    "        text += f\"\\n--- Chunk {chunk_num} (Pages {start+1}-{end}) ---\\n{chunk_text}\\n\"\n",
    "        chunk_num += 1\n",
    "\n",
    "    return Document(page_content=text, metadata={\"source\": file_name})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a3534f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"/Users/sameersingh/Documents/DataViz/data/Report on Title 2024-11-18.pdf\"\n",
    "\n",
    "# Example: 200 pages â†’ 10 pages per chunk â†’ 20 API calls (much faster than 200 calls)\n",
    "result_doc = extract_pdf_by_chunks(pdf_path, pages_per_chunk=10)\n",
    "\n",
    "print(result_doc.page_content[:2000])  # preview first 2000 chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f06cf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6372d6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mistralai import Mistral\n",
    "## method for ocr the scanned pdf\n",
    "def ocr_scanned_pdf(pdf_path : str) -> str:\n",
    "    \"\"\"ocr_scanned_pdf methhod is used for perform ocr on scanned pdf's.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): path of the files \n",
    "\n",
    "    Returns:\n",
    "        str: text of the ocr \n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"INFO : OCR start for file {pdf_path}\")\n",
    "        api_key = \"your api key\"\n",
    "        client = Mistral(api_key=api_key)\n",
    "        uploded_pdf = client.files.upload(\n",
    "        file={\n",
    "            \"file_name\":pdf_path,\n",
    "            \"content\":open(pdf_path,\"rb\")\n",
    "        },\n",
    "        purpose=\"ocr\"\n",
    "        )\n",
    "        client.files.retrieve(file_id=uploded_pdf.id)\n",
    "        signed_url = client.files.get_signed_url(file_id=uploded_pdf.id)\n",
    "        ocr_response = client.ocr.process(\n",
    "        model = \"mistral-ocr-latest\",\n",
    "        document={\n",
    "            \"type\" : \"document_url\",\n",
    "            \"document_url\" : signed_url.url,\n",
    "        },\n",
    "        include_image_base64=False\n",
    "        )\n",
    "        text =\"\"\n",
    "        for page in ocr_response.pages:\n",
    "            text = text + page.markdown + \"\\n\"\n",
    "            # print(page.markdown + \"\\\\n\")\n",
    "        print(f\"INFO : OCR completed for the file {pdf_path}\")\n",
    "        return text\n",
    "    except Exception as exp:\n",
    "        print(f\"ERROR : error in ocr_scanned_pdf : {exp}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081b8585",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ocr_scanned_pdf(\"/Users/sameersingh/Documents/DataViz/data/Construction_Contract_letters.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ffe24b",
   "metadata": {},
   "source": [
    "## loading data using python lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e426b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9e90f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text saved successfully in output.txt\n"
     ]
    }
   ],
   "source": [
    "# Save in a .txt file\n",
    "with open(\"Template.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(text)\n",
    "\n",
    "print(\"Text saved successfully in output.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd3c098",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_data_viz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
